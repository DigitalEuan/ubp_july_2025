#!/usr/bin/env python3
"""
UBP Operational Behavior Spectrum Analyzer
Comprehensive analysis of operational behavior across continuous spectrum
Author: Euan Craig (New Zealand) in collaboration with Manus AI
Date: July 3, 2025
"""

import math
import numpy as np
import json
from datetime import datetime
import matplotlib.pyplot as plt

class UBPSpectrumAnalyzer:
    def __init__(self):
        # Core operational constants (proven)
        self.core_constants = {
            'pi': math.pi,
            'phi': (1 + math.sqrt(5)) / 2,
            'e': math.e,
            'tau': 2 * math.pi
        }
        
        # Extended operational constants
        self.extended_constants = {
            'pi_e': math.pi ** math.e,
            'e_pi': math.e ** math.pi,
            'gelfond_schneider': 2 ** math.sqrt(2),
            'tau_phi': (2 * math.pi) ** ((1 + math.sqrt(5)) / 2),
            'sqrt_2': math.sqrt(2),
            'sqrt_3': math.sqrt(3),
            'euler_gamma': 0.5772156649015329,
            'catalan': 0.9159655941772190,
            'apery': 1.2020569031595943,
            'khinchin': 2.6854520010653064
        }
        
        # Physical constants
        self.physical_constants = {
            'light_speed': 299792458,
            'planck': 6.62607015e-34,
            'boltzmann': 1.380649e-23,
            'avogadro': 6.02214076e23,
            'fine_structure': 7.2973525693e-3,
            'electron_mass': 9.1093837015e-31,
            'proton_mass': 1.67262192369e-27,
            'gravitational': 6.67430e-11
        }
        
        # Spectrum thresholds for analysis
        self.spectrum_thresholds = [i/100.0 for i in range(0, 151, 1)]  # 0.00 to 1.50 in 0.01 increments
        
    def fibonacci_sequence(self, n, max_length=1000):
        """Generate Fibonacci sequence starting with n"""
        sequence = [n]
        current = n
        
        while len(sequence) < max_length and current != 1:
            if current % 2 == 0:
                current = current // 2
            else:
                current = 3 * current + 1
            sequence.append(current)
            
        return sequence
    
    def encode_to_24bit_offbits(self, sequence):
        """Encode sequence to 24-bit OffBits"""
        offbits = []
        for num in sequence:
            # Convert to 24-bit binary representation
            binary = format(num % (2**24), '024b')
            # Create OffBit (position where bit is 1)
            for i, bit in enumerate(binary):
                if bit == '1':
                    offbits.append(i)
        return offbits
    
    def calculate_3d_positions(self, offbits):
        """Calculate 3D positions in 24D Leech Lattice projection"""
        positions = []
        for offbit in offbits:
            # Map 24-bit position to 3D coordinates
            x = (offbit % 8) - 3.5
            y = ((offbit // 8) % 3) - 1
            z = (offbit // 24) - 0.5
            positions.append([x, y, z])
        return np.array(positions)
    
    def form_glyphs(self, positions, coherence_threshold=1.5):
        """Form Glyphs from 3D positions"""
        if len(positions) < 3:
            return []
        
        glyphs = []
        used_indices = set()
        
        for i in range(len(positions)):
            if i in used_indices:
                continue
                
            glyph = [i]
            for j in range(i+1, len(positions)):
                if j in used_indices:
                    continue
                    
                distance = np.linalg.norm(positions[i] - positions[j])
                if distance <= coherence_threshold:
                    glyph.append(j)
                    used_indices.add(j)
            
            if len(glyph) >= 3:  # Minimum 3 points for a Glyph
                glyphs.append(glyph)
                used_indices.add(i)
        
        return glyphs
    
    def calculate_s_pi(self, glyphs, positions):
        """Calculate S_Ï€ (geometric sum approaching Ï€)"""
        if not glyphs:
            return 0.0
        
        total_geometric_sum = 0.0
        
        for glyph in glyphs:
            if len(glyph) < 3:
                continue
                
            glyph_positions = positions[glyph]
            
            # Calculate angles between consecutive points
            angles = []
            for i in range(len(glyph_positions)):
                p1 = glyph_positions[i]
                p2 = glyph_positions[(i+1) % len(glyph_positions)]
                p3 = glyph_positions[(i+2) % len(glyph_positions)]
                
                v1 = p2 - p1
                v2 = p3 - p2
                
                # Calculate angle
                cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-10)
                cos_angle = np.clip(cos_angle, -1, 1)
                angle = np.arccos(cos_angle)
                angles.append(angle)
            
            # Sum angles for this Glyph
            glyph_sum = sum(angles)
            total_geometric_sum += glyph_sum
        
        return total_geometric_sum
    
    def calculate_operational_score_at_threshold(self, constant_value, threshold):
        """Calculate operational score for a constant at specific threshold"""
        try:
            # Generate Fibonacci-like sequence
            sequence = self.fibonacci_sequence(int(abs(constant_value * 100)) % 10000 + 1)
            
            # Encode to OffBits
            offbits = self.encode_to_24bit_offbits(sequence)
            
            if len(offbits) < 6:
                return 0.0
            
            # Calculate 3D positions
            positions = self.calculate_3d_positions(offbits)
            
            # Form Glyphs
            glyphs = self.form_glyphs(positions)
            
            if not glyphs:
                return 0.0
            
            # Calculate S_Ï€
            s_pi = self.calculate_s_pi(glyphs, positions)
            
            # Calculate operational metrics
            stability = len(glyphs) / max(len(offbits), 1)
            coupling = s_pi / (math.pi + 1e-10)
            resonance = abs(s_pi - math.pi) / math.pi
            
            # Threshold-adjusted scoring
            base_score = (stability + coupling + (1 - resonance)) / 3
            threshold_adjustment = 1.0 + (threshold * 0.5)  # Threshold sensitivity
            
            operational_score = base_score * threshold_adjustment
            
            return operational_score
            
        except Exception as e:
            return 0.0
    
    def analyze_spectrum_for_constant(self, constant_name, constant_value):
        """Analyze operational behavior across spectrum for single constant"""
        spectrum_data = {
            'constant_name': constant_name,
            'constant_value': constant_value,
            'spectrum_analysis': {}
        }
        
        for threshold in self.spectrum_thresholds:
            score = self.calculate_operational_score_at_threshold(constant_value, threshold)
            
            # Classify operational level
            if score >= 1.0:
                level = "Hyper-Operational"
            elif score >= 0.8:
                level = "Core Operational"
            elif score >= 0.6:
                level = "Strong Operational"
            elif score >= 0.3:
                level = "Standard Operational"
            elif score >= 0.1:
                level = "Weak Operational"
            else:
                level = "Passive"
            
            spectrum_data['spectrum_analysis'][threshold] = {
                'operational_score': score,
                'operational_level': level,
                'threshold_sensitivity': score / (threshold + 0.01)  # Avoid division by zero
            }
        
        return spectrum_data
    
    def comprehensive_spectrum_analysis(self):
        """Perform comprehensive spectrum analysis across all constants"""
        print("ðŸ”¬ UBP Operational Behavior Spectrum Analysis")
        print("=" * 60)
        print(f"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"Spectrum Range: 0.00 to 1.50 in 0.01 increments")
        print(f"Total Thresholds: {len(self.spectrum_thresholds)}")
        print()
        
        all_results = {
            'analysis_metadata': {
                'date': datetime.now().isoformat(),
                'spectrum_range': [0.0, 1.5],
                'increment': 0.01,
                'total_thresholds': len(self.spectrum_thresholds),
                'total_constants': 0
            },
            'core_constants': {},
            'extended_constants': {},
            'physical_constants': {},
            'spectrum_summary': {}
        }
        
        # Analyze core constants
        print("ðŸ“Š CORE CONSTANTS SPECTRUM ANALYSIS:")
        for name, value in self.core_constants.items():
            print(f"  Analyzing {name} = {value:.6f}...")
            spectrum_data = self.analyze_spectrum_for_constant(name, value)
            all_results['core_constants'][name] = spectrum_data
        
        print()
        
        # Analyze extended constants
        print("ðŸ“Š EXTENDED CONSTANTS SPECTRUM ANALYSIS:")
        for name, value in self.extended_constants.items():
            print(f"  Analyzing {name} = {value:.6f}...")
            spectrum_data = self.analyze_spectrum_for_constant(name, value)
            all_results['extended_constants'][name] = spectrum_data
        
        print()
        
        # Analyze physical constants (normalized)
        print("ðŸ“Š PHYSICAL CONSTANTS SPECTRUM ANALYSIS:")
        for name, value in self.physical_constants.items():
            # Normalize large physical constants
            normalized_value = value
            if abs(value) > 1000:
                normalized_value = math.log10(abs(value)) + (value / abs(value))
            elif abs(value) < 0.001:
                normalized_value = abs(value) * 1000
            
            print(f"  Analyzing {name} = {value:.6e} (normalized: {normalized_value:.6f})...")
            spectrum_data = self.analyze_spectrum_for_constant(name, normalized_value)
            all_results['physical_constants'][name] = spectrum_data
        
        # Calculate spectrum summary statistics
        all_results['analysis_metadata']['total_constants'] = (
            len(self.core_constants) + 
            len(self.extended_constants) + 
            len(self.physical_constants)
        )
        
        # Analyze spectrum patterns
        spectrum_summary = self.analyze_spectrum_patterns(all_results)
        all_results['spectrum_summary'] = spectrum_summary
        
        return all_results
    
    def analyze_spectrum_patterns(self, results):
        """Analyze patterns across the operational spectrum"""
        print("\nðŸ” SPECTRUM PATTERN ANALYSIS:")
        
        # Collect all operational scores across all constants and thresholds
        all_scores = []
        threshold_averages = {}
        
        for category in ['core_constants', 'extended_constants', 'physical_constants']:
            for constant_name, constant_data in results[category].items():
                for threshold, analysis in constant_data['spectrum_analysis'].items():
                    score = analysis['operational_score']
                    all_scores.append(score)
                    
                    if threshold not in threshold_averages:
                        threshold_averages[threshold] = []
                    threshold_averages[threshold].append(score)
        
        # Calculate threshold statistics
        threshold_stats = {}
        for threshold, scores in threshold_averages.items():
            threshold_stats[threshold] = {
                'mean_score': np.mean(scores),
                'std_score': np.std(scores),
                'max_score': np.max(scores),
                'min_score': np.min(scores),
                'operational_count': sum(1 for s in scores if s >= 0.3),
                'operational_percentage': (sum(1 for s in scores if s >= 0.3) / len(scores)) * 100
            }
        
        # Find critical thresholds
        critical_thresholds = []
        for i, threshold in enumerate(sorted(threshold_stats.keys())):
            if i > 0:
                prev_threshold = sorted(threshold_stats.keys())[i-1]
                current_op_pct = threshold_stats[threshold]['operational_percentage']
                prev_op_pct = threshold_stats[prev_threshold]['operational_percentage']
                
                if abs(current_op_pct - prev_op_pct) > 10:  # >10% change
                    critical_thresholds.append({
                        'threshold': threshold,
                        'change': current_op_pct - prev_op_pct,
                        'operational_percentage': current_op_pct
                    })
        
        # Overall statistics
        overall_stats = {
            'total_measurements': len(all_scores),
            'mean_operational_score': np.mean(all_scores),
            'std_operational_score': np.std(all_scores),
            'max_operational_score': np.max(all_scores),
            'min_operational_score': np.min(all_scores),
            'operational_rate_at_0.3': (sum(1 for s in all_scores if s >= 0.3) / len(all_scores)) * 100,
            'critical_thresholds': critical_thresholds,
            'threshold_statistics': threshold_stats
        }
        
        print(f"  Total Measurements: {overall_stats['total_measurements']}")
        print(f"  Mean Operational Score: {overall_stats['mean_operational_score']:.4f}")
        print(f"  Standard Deviation: {overall_stats['std_operational_score']:.4f}")
        print(f"  Operational Rate at 0.3: {overall_stats['operational_rate_at_0.3']:.2f}%")
        print(f"  Critical Thresholds Found: {len(critical_thresholds)}")
        
        return overall_stats
    
    def generate_spectrum_visualization(self, results):
        """Generate visualization of operational spectrum"""
        plt.figure(figsize=(15, 10))
        
        # Extract data for plotting
        thresholds = sorted(self.spectrum_thresholds)
        
        # Plot for each constant category
        categories = ['core_constants', 'extended_constants', 'physical_constants']
        colors = ['red', 'blue', 'green']
        
        for i, category in enumerate(categories):
            for constant_name, constant_data in results[category].items():
                scores = []
                for threshold in thresholds:
                    score = constant_data['spectrum_analysis'][threshold]['operational_score']
                    scores.append(score)
                
                plt.plot(thresholds, scores, color=colors[i], alpha=0.7, 
                        label=f"{category}: {constant_name}" if constant_name == list(results[category].keys())[0] else "")
        
        # Add threshold lines
        plt.axhline(y=0.3, color='orange', linestyle='--', alpha=0.8, label='Standard Operational (0.3)')
        plt.axhline(y=0.6, color='purple', linestyle='--', alpha=0.8, label='Strong Operational (0.6)')
        plt.axhline(y=0.8, color='brown', linestyle='--', alpha=0.8, label='Core Operational (0.8)')
        plt.axhline(y=1.0, color='black', linestyle='--', alpha=0.8, label='Hyper-Operational (1.0)')
        
        plt.xlabel('Threshold Value')
        plt.ylabel('Operational Score')
        plt.title('UBP Operational Behavior Spectrum Analysis')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        # Save visualization
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f'/home/ubuntu/ubp_spectrum_analysis_{timestamp}.png'
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        plt.close()
        
        return filename

def main():
    analyzer = UBPSpectrumAnalyzer()
    
    # Perform comprehensive spectrum analysis
    results = analyzer.comprehensive_spectrum_analysis()
    
    # Generate visualization
    viz_filename = analyzer.generate_spectrum_visualization(results)
    
    # Save results to JSON
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    results_filename = f'/home/ubuntu/ubp_spectrum_analysis_{timestamp}.json'
    
    with open(results_filename, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nâœ… SPECTRUM ANALYSIS COMPLETE!")
    print(f"ðŸ“Š Results saved to: {results_filename}")
    print(f"ðŸ“ˆ Visualization saved to: {viz_filename}")
    print(f"ðŸ”¬ Total measurements: {results['analysis_metadata']['total_constants'] * len(analyzer.spectrum_thresholds)}")
    
    return results_filename, viz_filename

if __name__ == "__main__":
    main()

